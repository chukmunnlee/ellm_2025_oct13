{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop 1 - Question and Answers\n",
    "In this workshop, you will learning how to write prompts and feed them into LLMs. You\n",
    "will also be learning how to use different prompt techniques to improve the response\n",
    "from the LLM.\n",
    "\n",
    "## Loading and Explorng the Dataset\n",
    "The workshop will be using [`facebook/ExploreToM`](https://huggingface.co/datasets/facebook/ExploreToM) dataset from [HuggingFace](https://huggingface.co)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the following libraries: datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset name\n",
    "dataset_name = \"facebook/ExploreToM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load and explore the dataset\n",
    "dataset = load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': (13309, 18)}\n",
      "dict_keys(['train'])\n",
      "{'story_structure': Value('string'), 'infilled_story': Value('string'), 'question': Value('string'), 'expected_answer': Value('string'), 'qprop=params': Value('string'), 'qprop=nth_order': Value('int64'), 'qprop=non_unique_mental_state': Value('bool'), 'sprop=is_false_belief_story_1st': Value('bool'), 'sprop=is_false_belief_story_1st_and_2nd': Value('bool'), 'sprop=story_accuracy_1st_raw': Value('float64'), 'sprop=story_accuracy_1st_infilled': Value('float64'), 'sprop=global_idx': Value('int64'), 'param=story_type': Value('string'), 'param=num_stories_total': Value('int64'), 'param=max_sentences': Value('int64'), 'param=num_people': Value('int64'), 'param=num_moves': Value('int64'), 'param=num_rooms': Value('int64')}\n",
      "Leslie entered the main tent. Leslie left the main tent. Isabella entered the storage trailer. Isabella moved the stuffed rabbit to the wooden chest, which is also located in the storage trailer. Leslie entered the main tent. Isabella moved the stuffed rabbit to the main tent, leaving the wooden chest in its original location. Isabella told out loud about the festival marketing strategies. Isabella told privately to Colton that Leslie is in the main tent. While this action was happening, Leslie witnessed this action in secret (and only this action).\n",
      "What does Isabella think about Colton's belief on festival marketing strategies? (knows about it / does not know about it)\n"
     ]
    }
   ],
   "source": [
    "# TODO: number of rows in the dataset\n",
    "print(dataset.shape)\n",
    "\n",
    "# TODO: Keys in the dataset\n",
    "print(dataset.keys())\n",
    "\n",
    "# TODO: Feature names\n",
    "print(dataset['train'].features)\n",
    "\n",
    "# TODO: Display a single row\n",
    "print(dataset['train'][100]['story_structure'])\n",
    "print(dataset['train'][100]['question'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import pipeline\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pipeline`\n",
    "[`pipeline`](https://huggingface.co/docs/transformers/en/main_classes/pipelines) is an easy to use API to perform inferencing. It provides a wrapper for task-specific pipelines and abstracts most of the complexity by allowing you to focus on the model and the task. \n",
    "\n",
    "You can use `pipeline` to perform summarisation, image classification, audio generation, etc. You can find an exhaustive list of `pipeline` task [here](https://huggingface.co/docs/transformers/en/main_classes/pipelines#transformers.pipeline.task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# TODO: Summarise the text with the pipeline's default model\n",
    "qna = pipeline('question-answering')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 50\n",
    "question = dataset['train'][idx]['question']\n",
    "story = dataset['train'][idx]['story_structure']\n",
    "story = dataset['train'][idx]['infilled_story']\n",
    "answer = dataset['train'][idx]['expected_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: The quiet production room was dimly lit by rows of flickering overhead lights, illuminating the space that was cluttered with equipment, scripts, and costume pieces. Toward the back, a large worktable sat against the wall, with shelves lined with plastic storage bins, a leather satchel, and cardboard boxes neatly stacked in the corner. With a quiet entrance, Lachlan joined the scattered equipment and supplies in the production room, the flickering overhead lights serving as a warm welcome. Brooklyn discreetly observed the lone figure reorganizing his supplies from behind a rack of costumes, noticing the script briefly visit a cardboard box before finding a permanent home in Lachlan's leather satchel. As Lachlan's task neared completion, the room welcomed two more figures, Brooklyn and Aubrey slipping in quietly, their eyes adapting to the dim lighting as they took in the organized chaos around them. Secure within a now carefully selected plastic storage bin on the shelves, the script was silently deposited by Brooklyn, almost an established part of its environment.\n",
      "Question: In which room does Lachlan think that Aubrey will search for the script?\n",
      "Generated answer: {'score': 0.08127623051404953, 'start': 420, 'end': 435, 'answer': 'production room'}\n",
      "Acutal answer: production room\n"
     ]
    }
   ],
   "source": [
    "result = qna(question=question, context=story)\n",
    "print(f'Context: {story}')\n",
    "print(f'Question: {question}')\n",
    "print(f'Generated answer: {result}')\n",
    "print(f'Acutal answer: {answer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Inference - Question and Answer\n",
    "In this section, we will look at what `pipeline` does under the hood to perform its inference. This will give us a better understanding of the major steps involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load tokenizer\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBERT base cased distilled SQuAD\n",
    "DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. More details [here](https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-cased-distilled-squad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,   157, 14640,  4103,  1136,  2561,   170,  3395,  1107,  1103,\n",
      "          1176,  1757,  1104,  1103,  1769,  1713,   119,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Encode text\n",
    "message = \"Thou shall not create a machine in the likeness of the human mind.\"\n",
    "\n",
    "# encode the message\n",
    "encoded = tokenizer(message, return_tensors='pt')\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,   157, 14640,  4103,  1136,  2561,   170,  3395,  1107,  1103,\n",
      "         1176,  1757,  1104,  1103,  1769,  1713,   119,   102])\n"
     ]
    }
   ],
   "source": [
    "enc_text = encoded.input_ids[0]\n",
    "print(enc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thou shall not create a machine in the likeness of the human mind.\n"
     ]
    }
   ],
   "source": [
    "orig_text = tokenizer.decode(enc_text, skip_special_tokens=True)\n",
    "print(orig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 = [CLS]\n",
      "157 = T\n",
      "14640 = ##hou\n",
      "4103 = shall\n",
      "1136 = not\n",
      "2561 = create\n",
      "170 = a\n",
      "3395 = machine\n",
      "1107 = in\n",
      "1103 = the\n",
      "1176 = like\n",
      "1757 = ##ness\n",
      "1104 = of\n",
      "1103 = the\n",
      "1769 = human\n",
      "1713 = mind\n",
      "119 = .\n",
      "102 = [SEP]\n"
     ]
    }
   ],
   "source": [
    "for t in enc_text:\n",
    "   tok = tokenizer.decode(t)\n",
    "   print(f'{t} = {tok}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Encoding multiple texts\n",
    "messages = [\n",
    "   \"big black bug bleeds black blood\",\n",
    "   \"Thou shall not create a machine in the likeness of the human mind.\"\n",
    "]\n",
    "\n",
    "encoded = tokenizer(messages, return_tensors='pt', padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1992,  1602, 15430, 24752,  1116,  1602,  1892,   102,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  101,   157, 14640,  4103,  1136,  2561,   170,  3395,  1107,  1103,\n",
      "          1176,  1757,  1104,  1103,  1769,  1713,   119,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "--------------------\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# TODO: Decode text\n",
    "print(encoded)\n",
    "print('--------------------')\n",
    "print(encoded.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] big black bug bleeds black blood [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS] Thou shall not create a machine in the likeness of the human mind. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(encoded.input_ids[0]))\n",
    "print(tokenizer.decode(encoded.input_ids[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with LLMs\n",
    "Create and instance of the Large Language Model (LLM). We will then create a simple\n",
    "prompt, tokenize the prompt and feed the tokenized prompt to the LLM. The response\n",
    "from the LLM will be decoded to human friendly text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load libraries\n",
    "from transformers import AutoModelForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does not know about it\n"
     ]
    }
   ],
   "source": [
    "# TODO: Load question answer model\n",
    "idx = 100\n",
    "question = dataset['train'][idx]['question']\n",
    "story = dataset['train'][idx]['story_structure']\n",
    "story = dataset['train'][idx]['infilled_story']\n",
    "answer = dataset['train'][idx]['expected_answer']\n",
    "print(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1327,  1674, 10206,  1341,  1164, 23065,   112,   188,  6369,\n",
      "          1113,  3782,  6213, 10700,   136,   113,  3520,  1164,  1122,   120,\n",
      "          1674,  1136,  1221,  1164,  1122,   114,   102,  1109,  3258,  8656,\n",
      "          1104,  5101,  4204, 15888,  1103, 18652,  5769,  1104,  1103,  3782,\n",
      "          4745,   117,  9616,   170, 21088,  6814,  1166, 10389,  1104, 12960,\n",
      "          1116,  1105, 14312,   119,   138,  7859,  5974,  1104,  3618, 13433,\n",
      "          1105,  6656, 20049, 20619,  1194,  1103,  1586,   117, 11241, 10134,\n",
      "          1114,  1103,  6531,  3807,  1104,  7053,  1105,  1390,   117,  1112,\n",
      "          1103,  1480,   112,   188, 24039,  1125,  1198,  4972,  1106,  8362,\n",
      "         10787,   119,  8521,  5002, 25649,  1154,  1103,  1514,  9459,   117,\n",
      "          1103,  3807,  1104,  1103,  3782,  1796, 17429, 17032,  1118,  1103,\n",
      "         11246,  2928,   119,  8521,  4144,  1763,  1103,  5134, 11246, 23841,\n",
      "          1116,   117, 17862,  1114,  1103, 21088,  3515,  1796,   117,  1147,\n",
      "          3999,  3170,  6532, 22604, 17429, 25752,  1181, 20746, 17814,  3782,\n",
      "          2758,  1468,   119,  1109,  5092,  9404,  1866,  4432,  1481,  1103,\n",
      "         12960,  1116,   117,  1157,  1442,  2494,   172, 22362,  1158,  1501,\n",
      "          1106,  5890, 10206,   119,  1249,  1131,  2242,   117,  1103,  3807,\n",
      "          1104,  7053,  1105,  1390,  2580, 10884,  1200,   117,  2125,  1118,\n",
      "          1103,  1538,  1183,  5974,  1104,  7905,  5508,  1105,  1103,  7859,\n",
      "           187,  8954,  1513,  1104,  8113,   119,  1249, 10206,  3876, 19587,\n",
      "          1103,  5092,  9404,   112,   188,  8792,   117,  1103, 12084, 16225,\n",
      "          1276,   170,  1207,  8137,  1282,  1120,  1103,  3248,  1104,  1103,\n",
      "          1385,  4122,  2229,   117,  1157,  2525,  1183,  1257,   176, 22761,\n",
      "          1158, 20525,  1107,  1103, 12563,  1609,   119,  8521,  1108,  6843,\n",
      "          1118,  1103,  1514,  9459,   112,   188, 12563,  1193,  4941,  4604,\n",
      "           117,  4016,  3525,  1103,   171,  8586, 25710,  1361,  6814,  1106,\n",
      "         21689,  1147,  5172,   117,  1196,  1231,  5521, 27884,  1154,  1103,\n",
      "          1480,   112,   188, 24039,  1796,   117,  3170,  6532, 22604,  1208,\n",
      "         27104,  2343,  1306,  8709,  1154,  1103, 17814, 13484,   119,  1249,\n",
      "         10206,  3175,  1103, 12084, 16225,  1106,  1103,  1514,  9459,   117,\n",
      "          1103, 21088, 13287,  2083,  1105,  1461,  1104,  1103,  3782,   112,\n",
      "           188, 23150, 17429, 14100,  1149,  1103,  1839,  1104,  1123, 10139,\n",
      "           117,  2128,  1103,  5092,  9404,   118,  1105,  1157,  4122,  2229,\n",
      "           118,  4432,  1481,   119,  1109,  8059,  1104,  1123,  1490, 11241,\n",
      "          8384,  1114,  1103,  1839,  1104,  7053,  1105,  1390,   117,  4004,\n",
      "         10206,   112,   188,  3578,  1113,  1103,  3782,   112,   188,  6213,\n",
      "          5250, 14291,  1116,  1149,  1506,  1103,  4745,   117,   170, 20049,\n",
      "         16364,  5126,  1104, 14222,  1286,  1107,  1123,  5314,   119, 10206,\n",
      "         22546,   170,  3802,  1106, 23065,   117,  1150, 18942,  1120,  1103,\n",
      "          2652,  1104,  1103,  3515,   117,  1123,  1257, 16348,  4016,  2135,\n",
      "          1117,  1112,  1131, 22546,   117,   112,  1124,   112,   188,  1171,\n",
      "          1107,  1103,  1514,  9459,   117,   112,  1105, 23065,   112,   188,\n",
      "          1257, 16945,   117, 25568,  1103,  3318,  3802,  1196,  1119,  1286,\n",
      "          1106,  1231, 14572,  1471,  1107,  1103,  3876,  1104,  1103,  1514,\n",
      "          9459,   119,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Encode context and question\n",
    "enc_qnc = tokenizer(question, story, return_tensors='pt', padding=True)\n",
    "print(enc_qnc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] What does Isabella think about Colton ' s belief on festival marketing strategies? ( knows about it / does not know about it ) [SEP] The warm glow of string lights illuminated the vibrant colors of the festival grounds, casting a lively atmosphere over rows of booths and attractions. A faint scent of popcorn and sugar wafted through the air, mingling with the distant sounds of laughter and music, as the night ' s festivities had just begun to unfold. Leslie slipped unnoticed into the main tent, the sounds of the festival outside momentarily muffled by the canvas walls. Leslie slid past the closing canvas flaps, merging with the lively crowd outside, their bright ringmaster attire momentarily camouflaged amidst swirling festivalgoers. The storage trailer stood quietly behind the booths, its door slowly creaking open to admit Isabella. As she entered, the sounds of laughter and music grew duller, replaced by the musty scent of stored supplies and the faint rustle of fabric. As Isabella rearranged the storage trailer ' s contents, the stuffed rabbit found a new resting place at the bottom of the old wooden chest, its glassy eyes glinting faintly in the dim light. Leslie was swallowed by the main tent ' s dimly lit interior, briefly allowing the boisterous atmosphere to conceal their movements, before reemerging into the night ' s festivities outside, ringmaster attire now blending seamlessly into the swirling crowds. As Isabella transferred the stuffed rabbit to the main tent, the lively chatter and song of the festival ' s attendees momentarily drowned out the sound of her footsteps, leaving the storage trailer - and its wooden chest - quietly behind. The warmth of her voice mingled with the sound of laughter and music, carrying Isabella ' s thoughts on the festival ' s marketing prowess out across the grounds, a wafting trail of insight left in her wake. Isabella mouthed a message to Colton, who lingered at the edge of the crowd, her eyes locking briefly onto his as she mouthed, ' He ' s back in the main tent, ' and Colton ' s eyes flickered, acknowledging the secret message before he left to reposition himself in the rear of the main tent. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Tokenize the inputs\n",
    "print(\n",
    "   tokenizer.decode(enc_qnc.input_ids[0])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the model \n",
    "result = model(enc_qnc.input_ids, enc_qnc.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['start_logits', 'end_logits'])\n",
      "QuestionAnsweringModelOutput(loss=None, start_logits=tensor([[  0.2511,  -7.3663,  -8.7323,  -7.2771,  -7.6361,  -8.9226,  -7.7561,\n",
      "          -9.7753,  -9.9385,  -7.6223,  -8.8285,  -8.2424,  -7.9430,  -8.6275,\n",
      "          -6.9744,  -4.0213,  -1.6666,  -6.4796,  -5.7669,  -4.8341,  -1.2666,\n",
      "          -2.7144,  -4.8449,  -7.2371,  -4.7256,  -6.9385,  -8.3332,  -7.8752,\n",
      "          -8.2298,  -9.6067, -10.9768,  -8.7236, -10.3558, -10.2204,  -9.9687,\n",
      "          -8.9472,  -9.7640, -10.9021,  -9.9693,  -9.0061, -10.3905, -10.7753,\n",
      "          -8.3033,  -8.5538,  -7.5416,  -9.2254, -10.2691,  -9.4027, -10.4673,\n",
      "          -8.8982, -11.5139, -10.7399,  -8.8208, -10.0034,  -8.3106,  -8.8129,\n",
      "          -9.8705, -11.0240,  -9.4240, -10.8961, -10.7609, -10.3907, -10.5220,\n",
      "         -11.7206, -11.2209, -11.1130, -11.1538, -11.5679,  -8.7850, -10.5699,\n",
      "         -10.8330,  -9.8103,  -9.0735, -10.2758, -11.1371,  -8.9919, -10.9623,\n",
      "          -9.6040, -11.2242,  -9.5187,  -8.8397,  -8.7780, -10.5124, -10.4374,\n",
      "          -9.4915, -10.7903, -10.4437, -10.4803, -10.4237,  -9.5510, -11.3668,\n",
      "         -10.2161,  -8.0002, -10.1550, -10.2612, -10.4025, -10.1403,  -9.3282,\n",
      "         -10.9558, -11.0136,  -8.8701,  -8.9573, -10.7821,  -9.9887, -10.0007,\n",
      "         -10.8330,  -9.5293,  -9.0479, -10.6817, -10.1008,  -8.9486, -10.3613,\n",
      "         -10.4181,  -7.5794, -10.3696, -10.6901, -10.7085,  -9.9010,  -9.9307,\n",
      "         -10.8680, -11.7627, -11.4000,  -9.2215, -10.5401,  -9.8592,  -8.7056,\n",
      "         -10.3853, -10.5855, -11.2005,  -8.7080,  -8.5302,  -9.4351, -11.3913,\n",
      "         -10.4130,  -9.6937,  -9.3346, -11.5500, -10.4610,  -9.2583,  -9.0964,\n",
      "         -10.8398, -11.1437, -10.8739,  -8.0026,  -8.8703, -11.1334, -10.9443,\n",
      "         -10.5080, -10.4750, -10.7001, -10.5126, -11.9574, -11.0063,  -7.6972,\n",
      "          -9.7334,  -8.9867,  -9.0980, -10.3257, -11.0095, -10.3375,  -9.2727,\n",
      "          -9.2908,  -7.0139, -11.0886,  -8.7934,  -9.6540, -10.2955, -10.4270,\n",
      "          -8.6694,  -8.9872, -10.6114,  -9.1566, -10.8318,  -9.7557, -10.5328,\n",
      "          -9.5999, -11.5123, -11.7673,  -9.5629, -10.7737,  -9.7862,  -8.9144,\n",
      "         -11.0160, -10.4451, -11.1656,  -9.7348, -11.0141, -10.5160, -10.0502,\n",
      "          -9.4686,  -9.7664, -11.4183, -11.6011, -10.8541, -10.3534, -10.9895,\n",
      "          -8.0210,  -6.1840,  -8.0346, -10.6676,  -9.9378,  -9.2360, -11.1913,\n",
      "         -10.7712, -10.8485, -10.4517, -11.0397,  -7.3640,  -7.5247,  -9.6864,\n",
      "         -10.1305,  -9.7035,  -9.4682,  -9.8809, -11.0750, -10.3769, -10.5104,\n",
      "         -10.2990, -10.1809, -10.4892,  -9.7951, -10.1636, -10.9796, -10.8560,\n",
      "          -7.7342,  -7.5815, -10.5517,  -9.3509,  -8.5239, -10.1400, -10.6781,\n",
      "          -9.4004,  -9.6210,  -9.6761,  -9.2492,  -9.9246,  -9.4558,  -6.2207,\n",
      "          -9.7706,  -8.4679,  -9.5598,  -8.8473,  -8.6574, -10.3192, -10.0532,\n",
      "         -10.3847,  -8.0681, -10.0429,  -9.5635,  -9.7226, -10.5257,  -7.6414,\n",
      "          -8.3826,  -8.2688,  -7.1520,  -9.9501, -10.0565, -10.6462,  -9.7299,\n",
      "          -9.3152,  -8.7646,  -9.8417,  -9.2035, -10.5369,  -7.5946,  -6.8941,\n",
      "          -9.1863,  -9.5999,  -8.9868,  -8.7670,  -8.5746,  -9.7715,  -9.9388,\n",
      "          -9.1847,  -9.6075, -10.2603,  -5.7117, -10.2707,  -9.4985,  -9.3419,\n",
      "          -8.0737,  -8.7413, -10.1047, -10.1792,  -8.8490,  -8.7707,  -7.4322,\n",
      "          -7.6296,  -9.1326,  -7.4873,  -6.1330,  -8.4379,  -9.1499,  -8.4093,\n",
      "          -9.8603,  -9.4031,  -9.5554,  -9.2218, -10.4850, -10.4178,  -7.6295,\n",
      "          -7.7710,  -8.5113, -10.3267,  -9.6944,  -8.9596, -10.1041,  -9.5564,\n",
      "          -9.1973, -10.1383, -10.4565,  -8.7602,  -8.5650,  -8.9416,  -9.7393,\n",
      "          -8.7967,  -8.7287,  -9.4530,  -8.1718,  -8.6228, -10.1281,  -8.0943,\n",
      "          -8.4297,  -8.1160, -10.1715, -10.3454,  -9.6607,  -9.5242,  -9.1126,\n",
      "          -9.9449, -10.3893,  -9.2926,  -9.5911,  -7.4176,  -0.8435,  -2.2888,\n",
      "          -7.6615,  -4.7923,  -5.5070,  -4.5121,  -7.7403,  -7.4174,  -5.2907,\n",
      "          -5.9603,  -8.0593,  -4.7455,  -8.5944,  -5.2853,  -8.0879,  -2.1955,\n",
      "          -0.1530,  -5.5469,  -5.1793,  -0.5666,  -3.7889,  -3.4021,  -3.8264,\n",
      "          -6.8308,  -6.3865,  -1.6923,  -2.4697,  -6.7565,  -7.5780,  -5.1886,\n",
      "          -7.0188,  -7.5850,  -6.9311,  -7.1131,   0.0349,  -1.9149,  -5.6660,\n",
      "          -4.2664,  -6.9333,  -4.0829,  -6.0833,  -6.5641,  -5.4478,  -6.5098,\n",
      "          -5.7053,   2.3817,  -0.0129,  -0.7797,  -2.7151,  -4.8456,  -3.5589,\n",
      "          -6.2554,  -4.0250,  -1.4411,  -4.6629,  -4.7946,  -7.1370,  -7.6483,\n",
      "          -6.1304,  -6.2629,  -7.2146,  -3.0272,  -4.5469,  -4.7274,  -1.1486,\n",
      "          -6.7826,  -2.5877,  -4.8329,  -1.9653,  -3.2055,  -7.3478,  -7.9644,\n",
      "          -4.0344,  -8.3784,  -8.7104,  -7.3666,  -6.6750,  -7.2529,  -8.1143,\n",
      "          -8.0969,  -7.8515,  -8.8783,  -7.4519,  -3.8137,  -8.2931,  -8.8176,\n",
      "          -5.6759,  -2.7486,  -7.5459,  -3.1978,  -6.8331,  -5.1472,  -5.5412,\n",
      "          -6.0134,  -2.1593,  -4.7950,  -7.3045,  -6.1742,  -7.1758,  -6.0330,\n",
      "          -6.1945,  -6.6710,  -6.0018,  -8.3020,  -6.8705,  -7.4953,  -7.0073,\n",
      "          -6.9857,  -8.3332]], grad_fn=<CloneBackward0>), end_logits=tensor([[  0.7351,  -7.9387,  -9.7109,  -7.8906,  -7.9472,  -9.4412,  -8.2666,\n",
      "          -8.9494,  -8.9537,  -8.0731,  -9.5664,  -9.1391,  -8.0440,  -6.2540,\n",
      "          -6.6492,  -7.8264,  -5.4565,  -7.3174,  -2.3196,  -6.6458,  -8.0162,\n",
      "          -3.9055,  -2.0365,  -5.2695,  -0.0807,  -3.3384,  -8.9243, -10.7970,\n",
      "          -9.9816,  -9.9321, -11.2110,  -9.8359,  -8.6027, -10.3192, -10.5298,\n",
      "          -9.7196,  -7.9578, -10.5896, -10.6491,  -9.1956,  -6.4580,  -8.0424,\n",
      "         -10.6062, -10.7304,  -8.9149,  -7.2382, -10.6318,  -9.3828, -10.2756,\n",
      "          -9.8824,  -7.8378, -10.0983,  -6.7032,  -7.2025, -11.0418, -10.3973,\n",
      "         -10.1751, -11.5818, -11.4883,  -9.7292, -11.0891,  -9.0201, -11.7735,\n",
      "         -10.4257, -11.1916, -11.0113,  -8.2353,  -8.9365, -11.0924,  -9.9583,\n",
      "         -10.9988, -11.3833, -10.3147, -10.2688, -11.2203,  -8.9234, -10.7398,\n",
      "          -7.2396,  -7.9687, -10.8258, -11.2602,  -9.6919, -10.4145,  -9.9562,\n",
      "          -9.1427, -10.7023, -10.4987, -10.2676, -10.3443, -10.2862,  -8.0394,\n",
      "          -7.8390,  -8.6500, -10.3872,  -9.2877, -10.4675, -10.7349, -10.1177,\n",
      "          -7.6665,  -8.7002, -10.6839,  -9.3100, -11.0094, -11.4555, -10.0938,\n",
      "          -8.8937, -10.0537,  -8.9117, -10.2666, -10.7259,  -9.3563,  -7.1239,\n",
      "          -8.4729,  -8.2186, -10.4273, -10.4907, -10.8069, -10.2214,  -9.8884,\n",
      "         -10.7056,  -8.0550,  -8.6495,  -9.9186, -10.5424, -11.2429,  -9.9620,\n",
      "          -8.9379,  -7.8565,  -8.5074, -10.6702, -10.1178, -11.1911,  -8.5315,\n",
      "          -8.3625,  -9.9269, -10.0268,  -8.1677,  -9.7546,  -9.4540,  -9.9454,\n",
      "         -10.6057,  -6.7556,  -7.9641, -11.2123, -10.4087,  -8.7526, -10.1029,\n",
      "          -9.2514, -10.5050, -10.5269, -10.7470,  -7.6303,  -8.8248, -11.0578,\n",
      "          -9.4946,  -9.5437, -10.6817, -10.0478,  -9.1044,  -7.6426,  -9.8030,\n",
      "          -8.9051,  -5.3953,  -7.3083, -11.3192, -10.3975,  -8.6794,  -9.5234,\n",
      "         -11.3862, -10.3721, -10.8528,  -9.1082, -10.4118,  -8.8125, -10.9488,\n",
      "         -10.3539,  -7.0194,  -8.3827,  -9.7082, -10.4829, -11.5473, -10.6030,\n",
      "         -10.2052, -10.0503, -11.0836, -10.8026,  -8.0889,  -9.9004, -11.2003,\n",
      "         -10.4648, -11.3402, -10.7564, -10.1197, -10.5642,  -7.8564,  -7.7093,\n",
      "          -9.9953,  -8.2764, -10.6348,  -9.2253, -10.7637, -10.2582,  -9.0279,\n",
      "          -9.3298,  -9.0253,  -6.9221,  -7.7766, -10.9367, -10.3139,  -6.3964,\n",
      "          -9.9990, -10.3017,  -9.7958,  -9.5095,  -8.2579, -10.1841, -10.4877,\n",
      "          -9.1070,  -9.4765, -10.3287,  -9.8725,  -9.7191,  -7.3170,  -7.7275,\n",
      "         -10.1530,  -9.8112,  -8.9818,  -7.7174, -10.1926,  -9.4518,  -8.5520,\n",
      "          -8.4010, -10.0598,  -9.9614,  -9.4671,  -6.2585,  -6.2785,  -7.2830,\n",
      "          -8.7282,  -8.3517,  -9.2962, -10.4932, -10.1142,  -8.4321,  -9.0476,\n",
      "          -8.5045,  -9.9095,  -9.1216,  -8.4456,  -6.2235,  -6.9389,  -8.9022,\n",
      "          -9.8854, -10.3220, -10.5521, -10.2013, -10.0579,  -7.1343,  -7.0006,\n",
      "          -9.1976,  -8.3976,  -8.7739,  -5.7200,  -6.4401,  -8.3386,  -9.4932,\n",
      "          -8.8806,  -8.0797,  -8.8512,  -9.7300,  -8.4383,  -8.5271,  -7.9166,\n",
      "          -6.8422,  -5.7051,  -6.8962,  -9.3271,  -6.9237,  -7.2254,  -8.7141,\n",
      "          -8.5027,  -9.5546,  -9.0086,  -6.7227,  -8.4056,  -9.1481,  -7.9669,\n",
      "          -3.2985,  -3.9022,  -9.0886,  -7.9086,  -9.3069, -10.6245, -10.3421,\n",
      "          -6.4623,  -9.0723,  -9.7819,  -9.4947,  -6.3432,  -6.8729, -10.1012,\n",
      "          -9.0736,  -9.4353,  -7.5669,  -9.2205,  -8.1025,  -9.5251, -10.3921,\n",
      "          -8.9432,  -8.9094,  -8.3734,  -7.5268,  -9.1227,  -9.2344,  -8.6171,\n",
      "          -9.2018,  -7.6165,  -9.0378,  -8.8157,  -5.8437,  -6.4031,  -9.2059,\n",
      "         -10.4346,  -9.6828,  -6.7292,  -8.3458,  -8.9262,  -9.4230,  -9.0691,\n",
      "          -7.6468,  -8.0882,  -7.9853,  -6.4122,  -3.7524,  -6.3114,  -3.8431,\n",
      "          -7.7055,  -6.4169,  -2.0706,  -7.3701,  -4.2916,  -8.3019,  -8.9326,\n",
      "          -6.6191,  -8.7542,  -4.5328,  -8.5067,  -1.4409,  -3.2678,  -6.0830,\n",
      "          -3.6383,  -5.5006,  -2.8645,  -1.2152,  -6.1100,  -7.5186,  -5.4304,\n",
      "          -6.9841,  -5.2802,  -3.5562,  -6.1132,  -5.9783,  -1.8425,  -4.2381,\n",
      "          -6.0615,  -7.3217,  -0.0868,  -1.9649,  -6.7577,  -7.3318,  -5.5475,\n",
      "          -3.4640,  -7.4435,  -0.7135,  -3.2219,  -7.0378,  -5.4602,   0.0192,\n",
      "           0.1689,  -2.4953,  -1.6156,  -5.2274,   2.0675,  -3.6216,  -0.9724,\n",
      "          -0.7575,  -3.9725,  -1.7383,  -4.7664,  -7.4760,  -2.5927,  -6.7473,\n",
      "          -8.4398,  -2.5581,  -1.9499,  -5.6887,  -1.5655,  -4.2875,  -1.4672,\n",
      "          -4.6856,  -5.8416,  -5.6893,  -3.9737,  -2.3394,  -2.0271,  -5.9192,\n",
      "          -4.6344,  -6.6173,  -4.2796,  -3.2107,  -5.9205,  -8.2762,  -6.6796,\n",
      "          -5.4139,  -2.6036,  -5.7018,  -6.4504,  -2.7976,  -6.3465,  -3.7526,\n",
      "          -1.6269,  -4.2722,  -2.0381,  -3.8668,  -8.0244,  -3.2403,  -1.2772,\n",
      "          -6.0633,  -4.8518,  -4.2556,  -6.4083,  -5.3356,  -3.1580,  -1.6256,\n",
      "          -6.2350,  -8.2918,  -5.4314,  -6.5996,  -8.2326,  -6.0487,  -4.4321,\n",
      "          -0.2787,  -8.9243]], grad_fn=<CloneBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(result.keys())\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(379)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# find the index of the largest value in start_logit\n",
    "ans_start = torch.argmax(result.start_logits)\n",
    "print(ans_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(383)\n"
     ]
    }
   ],
   "source": [
    "# find the index of the largest value in end_logit\n",
    "ans_end = torch.argmax(result.end_logits) + 1\n",
    "print(ans_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10206, 22546,   170,  3802])\n",
      "Isabella mouthed a message\n",
      "----------------\n",
      "\n",
      "Question: What does Isabella think about Colton's belief on festival marketing strategies? (knows about it / does not know about it)\n",
      "Context: The warm glow of string lights illuminated the vibrant colors of the festival grounds, casting a lively atmosphere over rows of booths and attractions. A faint scent of popcorn and sugar wafted through the air, mingling with the distant sounds of laughter and music, as the night's festivities had just begun to unfold. Leslie slipped unnoticed into the main tent, the sounds of the festival outside momentarily muffled by the canvas walls. Leslie slid past the closing canvas flaps, merging with the lively crowd outside, their bright ringmaster attire momentarily camouflaged amidst swirling festivalgoers. The storage trailer stood quietly behind the booths, its door slowly creaking open to admit Isabella. As she entered, the sounds of laughter and music grew duller, replaced by the musty scent of stored supplies and the faint rustle of fabric. As Isabella rearranged the storage trailer's contents, the stuffed rabbit found a new resting place at the bottom of the old wooden chest, its glassy eyes glinting faintly in the dim light. Leslie was swallowed by the main tent's dimly lit interior, briefly allowing the boisterous atmosphere to conceal their movements, before reemerging into the night's festivities outside, ringmaster attire now blending seamlessly into the swirling crowds. As Isabella transferred the stuffed rabbit to the main tent, the lively chatter and song of the festival's attendees momentarily drowned out the sound of her footsteps, leaving the storage trailer - and its wooden chest - quietly behind. The warmth of her voice mingled with the sound of laughter and music, carrying Isabella's thoughts on the festival's marketing prowess out across the grounds, a wafting trail of insight left in her wake. Isabella mouthed a message to Colton, who lingered at the edge of the crowd, her eyes locking briefly onto his as she mouthed, 'He's back in the main tent,' and Colton's eyes flickered, acknowledging the secret message before he left to reposition himself in the rear of the main tent.\n",
      "Answer: Isabella mouthed a message\n"
     ]
    }
   ],
   "source": [
    "enc_ans = enc_qnc.input_ids[0][ans_start: ans_end]\n",
    "print(enc_ans)\n",
    "answer = tokenizer.decode(enc_ans)\n",
    "print(answer)\n",
    "print('----------------\\n')\n",
    "print(f'Question: {question}')\n",
    "print(f'Context: {story}')\n",
    "print(f'Answer: {answer}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_workhop_templates",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
